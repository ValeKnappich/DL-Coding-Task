{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DL Coding Task This repository contains my solution to the deep learning coding task from Prof. Vu. Scripts config.py : File that contains constants like UNIQUE_INTENTS and mappings to IDs. Also contains hyperparameters. model.py : Defines the model as PyTorch Lightning Module and therefore implements the model architecture, as well as training and validation procedure. Model is saved after training. train.py : Used to train the model with a pl.Trainer. Uses multiple GPU's if available and performs early stopping. data.py : Defines the pl.LightningDataModule, that implements data loading and preprocessing. Executing the script will run and end-to-end test, weather the conversion between formats worked correctly for the training data. test.py : Used to perform inference on the dev set. Usage python train.py # train the model, checkpoint is saved to disk python test.py # loads the dumped model, predicts the classes and outputs the results to disk","title":"Home"},{"location":"#dl-coding-task","text":"This repository contains my solution to the deep learning coding task from Prof. Vu.","title":"DL Coding Task"},{"location":"#scripts","text":"config.py : File that contains constants like UNIQUE_INTENTS and mappings to IDs. Also contains hyperparameters. model.py : Defines the model as PyTorch Lightning Module and therefore implements the model architecture, as well as training and validation procedure. Model is saved after training. train.py : Used to train the model with a pl.Trainer. Uses multiple GPU's if available and performs early stopping. data.py : Defines the pl.LightningDataModule, that implements data loading and preprocessing. Executing the script will run and end-to-end test, weather the conversion between formats worked correctly for the training data. test.py : Used to perform inference on the dev set.","title":"Scripts"},{"location":"#usage","text":"python train.py # train the model, checkpoint is saved to disk python test.py # loads the dumped model, predicts the classes and outputs the results to disk","title":"Usage"},{"location":"api-reference/","text":"model IntentAndEntityModel Objects class IntentAndEntityModel(pl.LightningModule) forward | forward(input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor] Forward pass Arguments : input_ids torch.Tensor - [description] attention_mask torch.Tensor - [description] Returns : intent_logits, ner_logits (Tuple[torch.Tensor, torch.Tensor]): Logits of the intent and NER heads before Softmax configure_optimizers | configure_optimizers() -> Tuple[ | List[torch.optim.Optimizer], List[torch.optim.lr_scheduler._LRScheduler] | ] Configure optimizer and lr scheduler Returns : Tuple[List[torch.optim.Optimizer], List[torch.optim.lr_scheduler._LRScheduler]]: [description] loss | loss(intent_logits: torch.Tensor, ner_logits: torch.Tensor, intent_labels: torch.Tensor, ner_labels: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor] Calculate the individual losses for intent and ner respectively Arguments : intent_logits torch.Tensor - [description] ner_logits torch.Tensor - [description] intent_labels torch.Tensor - [description] ner_labels torch.Tensor - [description] Returns : Tuple[torch.Tensor, torch.Tensor]: [description] accuracy | accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float Calculate accuracy for logits and labels Arguments : logits torch.Tensor - [description] labels torch.Tensor - [description] Returns : float - [description] training_step | training_step(batch: dict, batch_idx: int) -> torch.Tensor Training step Arguments : batch dict - [description] batch_idx int - [description] Returns : torch.Tensor - [description] validation_step | validation_step(batch: dict, batch_idx: int) Validation step Arguments : batch dict - [description] batch_idx int - [description] config data NLUDataSet Objects class NLUDataSet(Dataset) Generic Dataset, that holds a dict with columns. Columns are typed as long. Arguments : Dataset dict - dict holding the columns DataModule Objects class DataModule(pl.LightningDataModule) Data Module to load data from disk and create DataLoaders Arguments : pl [type] - [description] load_and_clean | load_and_clean() -> dict Load data from disk and remove characters that are not supported by the tokenizer Returns : data (dict): train","title":"API Reference"},{"location":"api-reference/#model","text":"","title":"model"},{"location":"api-reference/#intentandentitymodel-objects","text":"class IntentAndEntityModel(pl.LightningModule)","title":"IntentAndEntityModel Objects"},{"location":"api-reference/#forward","text":"| forward(input_ids: torch.Tensor, attention_mask: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor] Forward pass Arguments : input_ids torch.Tensor - [description] attention_mask torch.Tensor - [description] Returns : intent_logits, ner_logits (Tuple[torch.Tensor, torch.Tensor]): Logits of the intent and NER heads before Softmax","title":"forward"},{"location":"api-reference/#configure_optimizers","text":"| configure_optimizers() -> Tuple[ | List[torch.optim.Optimizer], List[torch.optim.lr_scheduler._LRScheduler] | ] Configure optimizer and lr scheduler Returns : Tuple[List[torch.optim.Optimizer], List[torch.optim.lr_scheduler._LRScheduler]]: [description]","title":"configure_optimizers"},{"location":"api-reference/#loss","text":"| loss(intent_logits: torch.Tensor, ner_logits: torch.Tensor, intent_labels: torch.Tensor, ner_labels: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor] Calculate the individual losses for intent and ner respectively Arguments : intent_logits torch.Tensor - [description] ner_logits torch.Tensor - [description] intent_labels torch.Tensor - [description] ner_labels torch.Tensor - [description] Returns : Tuple[torch.Tensor, torch.Tensor]: [description]","title":"loss"},{"location":"api-reference/#accuracy","text":"| accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float Calculate accuracy for logits and labels Arguments : logits torch.Tensor - [description] labels torch.Tensor - [description] Returns : float - [description]","title":"accuracy"},{"location":"api-reference/#training_step","text":"| training_step(batch: dict, batch_idx: int) -> torch.Tensor Training step Arguments : batch dict - [description] batch_idx int - [description] Returns : torch.Tensor - [description]","title":"training_step"},{"location":"api-reference/#validation_step","text":"| validation_step(batch: dict, batch_idx: int) Validation step Arguments : batch dict - [description] batch_idx int - [description]","title":"validation_step"},{"location":"api-reference/#config","text":"","title":"config"},{"location":"api-reference/#data","text":"","title":"data"},{"location":"api-reference/#nludataset-objects","text":"class NLUDataSet(Dataset) Generic Dataset, that holds a dict with columns. Columns are typed as long. Arguments : Dataset dict - dict holding the columns","title":"NLUDataSet Objects"},{"location":"api-reference/#datamodule-objects","text":"class DataModule(pl.LightningDataModule) Data Module to load data from disk and create DataLoaders Arguments : pl [type] - [description]","title":"DataModule Objects"},{"location":"api-reference/#load_and_clean","text":"| load_and_clean() -> dict Load data from disk and remove characters that are not supported by the tokenizer Returns : data (dict):","title":"load_and_clean"},{"location":"api-reference/#train","text":"","title":"train"},{"location":"approach/","text":"Approach","title":"Approach Overview"},{"location":"approach/#approach","text":"","title":"Approach"},{"location":"results/","text":"Results","title":"Results"},{"location":"results/#results","text":"","title":"Results"},{"location":"task/","text":"Task Overview The task is to predict the intent and entities in user utterances. Data Format Labelled training data and unlabelled test data. { \"0\": { \"intent\": \"AddToPlaylist\", \"text\": \"Add a tune to my elrow Guest List\", \"slots\": { \"music_item\": \"tune\", \"playlist_owner\": \"my\", \"playlist\": \"elrow Guest List\" }, \"positions\": { \"music_item\": [ 6, 9 ], \"playlist_owner\": [ 14, 15 ], \"playlist\": [ 17, 32 ] } } }","title":"Task Overview"},{"location":"task/#task-overview","text":"The task is to predict the intent and entities in user utterances.","title":"Task Overview"},{"location":"task/#data-format","text":"Labelled training data and unlabelled test data. { \"0\": { \"intent\": \"AddToPlaylist\", \"text\": \"Add a tune to my elrow Guest List\", \"slots\": { \"music_item\": \"tune\", \"playlist_owner\": \"my\", \"playlist\": \"elrow Guest List\" }, \"positions\": { \"music_item\": [ 6, 9 ], \"playlist_owner\": [ 14, 15 ], \"playlist\": [ 17, 32 ] } } }","title":"Data Format"}]}